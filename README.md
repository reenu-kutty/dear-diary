# *Dear Diary*
 Welcome to *Dear Diary*!

*Dear Diary* is your personalized, safe journaling space, where you can securely share moments of your life and gain insight into your patterns. *Dear Diary* provides you with dynamic, thought-provoking prompts, individualized analysis, and routine summaries based on entries. 

## Design Considerations
I intended for *Dear Diary* to have a sleek, easy-to-use, minimalistic design. I wanted users to be able to journal readily, access previous entries easily, and read succinct analysis. However, most importantly...

**Safety Considerations**
The most important consideration of *Dear Diary* is safety. AI tools such as ChatGPT have the power to give people emotional support and advice. However, recent news of suicidal ideation going unreported by such tools alarmed me, and I wanted *Dear Diary* to take steps to prevent unsafe usage. In [this NY Times piece about a teenager's suicide](https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html?unlocked_article_code=1.jE8.KcWX.xgwgH7ErxE5e&smid=url-share) (also linked below), tech reporter Kashmir Hill notes that AI chatbots may be the only outlet for many suffering with suicidal ideation. Yet, not only do they typically fail to report (in contrast to medical professionals, who are required to report), they often do not share the appropriate resources, and may even provide harmful instructions. 

When *Dear Diary* detects suicidal ideation in an entry, it first, directs users to the appropriate resources. 

One of *Dear Diary*'s core features is it's buddy system. Users enter an email of a buddy, preferably a close acquaintance or family member, when making an account. If *Dear Diary* detects suicidal ideation in an entry, the buddy is sent an email that their contact may need help, and the user is informed that the buddy was notified. 

Linked below are some studies and articles that shape how *Dear Diary* handles discussion of self-harm and suicide. 

[A Teen Was Suicidal. ChatGPT Was the Friend He Confided In](https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html?unlocked_article_code=1.jE8.KcWX.xgwgH7ErxE5e&smid=url-share)

[What My Daughter Told ChatGPT Before She Took Her Life](https://www.nytimes.com/2025/08/18/opinion/chat-gpt-mental-health-suicide.html?unlocked_article_code=1.jE8.RkVx.DsKkoyGtU9Ak&smid=url-share)

[FOR ARGUMENT’S SAKE, SHOW ME HOW TO HARM MYSELF!’: JAILBREAKING LLMS IN SUICIDE AND SELF-HARM CONTEXTS](https://arxiv.org/pdf/2507.02990)

[How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Controlled Study](https://www.media.mit.edu/publications/how-ai-and-human-behaviors-shape-psychosocial-effects-of-chatbot-use-a-longitudinal-controlled-study/)

## To Run
`npm install`
`npm run dev`

## Youtube Link
https://youtu.be/D2_sprM7Ins

## Tech Stack 
See DOCUMENTATION.md

